id,alias,name,status,input_price,output_price,cache_input_price,context_window,max_output,capabilities,quality,source,updated,description,mmlu_score,humaneval_score,math_score
llama/llama-3.2-90b-vision-instruct,llama-3.2-90b-vision,Meta: Llama 3.2 90B Vision,C,0.00000090,0.00000900,-,8192,4096,VST,verified,together,2025-01-04,Llama 3.2 90B with native vision understanding for images and charts,-,-,-
llama/llama-3.2-11b-vision-instruct,llama-3.2-11b-vision,Meta: Llama 3.2 11B Vision,C,0.00000007,0.00000070,-,8192,4096,VST,verified,together,2025-01-04,Compact Llama 3.2 vision model optimized for edge deployment,-,-,-
qwen/qwen2.5-vl-7b-instruct,qwen2.5-vl-7b,Alibaba: Qwen2.5-VL 7B,C,0.00000004,0.00000040,-,8192,2048,VST,verified,alibaba,2025-01-02,Qwen 2.5 Vision Language 7B model with OCR capabilities,-,-,-
qwen/qwen2.5-vl-32b-instruct,qwen2.5-vl-32b,Alibaba: Qwen2.5-VL 32B,C,0.00000015,0.00000150,-,16384,4096,VST,verified,alibaba,2025-01-02,Qwen 2.5 Vision Language 32B with enhanced visual understanding,-,-,-
qwen/qwen-vl-plus,qwen-vl-plus,Alibaba: Qwen VL Plus,C,0.00000050,0.00000500,-,20000,4096,VST,verified,alibaba,2024-12-15,Production-grade Qwen vision model for enterprise applications,-,-,-
qwen/qwen-vl-max,qwen-vl-max,Alibaba: Qwen VL Max,C,0.00000100,0.00001000,-,32000,8192,VST,verified,alibaba,2024-12-15,Most capable Qwen vision model with 4K image support,-,-,-
baidu/ernie-4v-8k,ernie-4v-8k,Baidu: ERNIE 4.0 Vision,C,0.00000080,0.00000800,-,8192,2048,VST,verified,baidu,2024-12-10,Baidu multimodal model for Chinese and English vision tasks,-,-,-
baidu/ernie-4v-32k,ernie-4v-32k,Baidu: ERNIE 4.0 Vision 32K,C,0.00000150,0.00001500,-,32000,4096,VST,verified,baidu,2024-12-10,Extended context Baidu vision model,-,-,-
mistral/pixtral-large,pixtral-large,Mistral: Pixtral Large,C,0.00000200,0.00000600,-,64000,2048,VST,verified,mistral,2024-12-20,Mistral native multimodal model for advanced vision tasks,-,-,-
mistral/pixtral-12b,pixtral-12b,Mistral: Pixtral 12B,C,0.00000030,0.00000100,-,8192,1024,VST,verified,mistral,2024-12-20,Efficient 12B vision model from Mistral,-,-,-
google/gemini-2.5-vision,gemini-2.5-vision,Google: Gemini 2.5 Vision,C,0.00000375,0.00001500,-,1000000,8192,VSTJK,verified,google,2025-01-03,Gemini 2.5 with advanced visual understanding and reasoning,-,-,-
google/gemini-1.5-vision,gemini-1.5-vision,Google: Gemini 1.5 Vision,L,0.00000250,0.00000750,-,1000000,4096,VSTJ,verified,google,2024-12-01,Previous-generation Gemini vision model,-,-,-
openai/gpt-4-vision,gpt-4-vision,OpenAI: GPT-4 Vision,L,0.00001000,0.00003000,-,128000,4096,VST,verified,openai,2024-11-01,Legacy GPT-4 with vision capability,-,-,-
openai/gpt-4-turbo-vision,gpt-4-turbo-vision,OpenAI: GPT-4 Turbo Vision,L,0.00001000,0.00003000,-,128000,4096,VST,verified,openai,2024-11-01,GPT-4 Turbo with vision support,-,-,-
anthropic/claude-3-opus-vision,claude-3-opus-vision,Anthropic: Claude 3 Opus Vision,L,0.01500000,0.07500000,-,200000,4096,VSTJKC,verified,anthropic,2024-03-01,Original Claude 3 Opus with vision,-,-,-
anthropic/claude-3-sonnet-vision,claude-3-sonnet-vision,Anthropic: Claude 3 Sonnet Vision,L,0.00300000,0.01500000,-,200000,4096,VSTJKC,verified,anthropic,2024-03-01,Claude 3 Sonnet with vision capabilities,-,-,-
together/llava-1.6-34b,llava-1.6-34b,Together: LLaVA 1.6 34B,C,0.00000080,0.00000800,-,4096,2048,VST,verified,together,2024-11-15,Open-source LLaVA vision model with 34B parameters,-,-,-
together/llava-1.6-13b,llava-1.6-13b,Together: LLaVA 1.6 13B,C,0.00000025,0.00000250,-,4096,2048,VST,verified,together,2024-11-15,Efficient LLaVA vision model with 13B parameters,-,-,-
together/llava-onevision-7b,llava-onevision-7b,Together: LLaVA OneVision 7B,C,0.00000007,0.00000070,-,4096,1024,VST,verified,together,2024-12-01,Latest LLaVA OneVision compact model,-,-,-
together/llava-onevision-72b,llava-onevision-72b,Together: LLaVA OneVision 72B,C,0.00000150,0.00001500,-,4096,4096,VST,verified,together,2024-12-01,Large-scale LLaVA OneVision model,-,-,-
bedrock/claude-3.5-sonnet-vision,bedrock-claude-3.5-vision,AWS: Claude 3.5 Sonnet Vision,C,0.00300000,0.01500000,-,200000,4096,VSTJKC,verified,bedrock,2025-01-03,Claude 3.5 Sonnet deployed via AWS Bedrock,-,-,-
bedrock/amazon-nova-pro-vision,bedrock-nova-pro-vision,AWS: Nova Pro Vision,C,0.00080000,0.00320000,-,300000,5000,VSTJ,verified,bedrock,2024-12-15,Amazon Nova Pro multimodal model via Bedrock,-,-,-
bedrock/amazon-nova-lite-vision,bedrock-nova-lite-vision,AWS: Nova Lite Vision,C,0.00006000,0.00024000,-,300000,5000,VSTJ,verified,bedrock,2024-12-15,Lightweight Nova vision model,-,-,-
azure/gpt-4-turbo-vision,azure-gpt-4-turbo-vision,Azure: GPT-4 Turbo Vision,C,0.00001000,0.00003000,-,128000,4096,VST,verified,azure,2024-11-01,GPT-4 Turbo with vision via Azure OpenAI,-,-,-
azure/gpt-4o-vision,azure-gpt-4o-vision,Azure: GPT-4o Vision,C,0.00250000,0.01000000,-,128000,16384,VSTJS,verified,azure,2024-12-01,GPT-4o deployed via Azure with vision,-,-,-
vertex/claude-3.5-sonnet-vision,vertex-claude-vision,GCP: Claude 3.5 Sonnet Vision,C,0.00300000,0.01500000,-,200000,4096,VSTJKC,verified,vertex,2025-01-03,Claude 3.5 Sonnet via Google Cloud Vertex AI,-,-,-
vertex/gemini-2.5-vision-exp,vertex-gemini-vision-exp,GCP: Gemini 2.5 Vision Exp,C,0.00000250,0.00000750,-,1000000,8192,VSTJK,verified,vertex,2024-12-20,Experimental Gemini 2.5 vision via Vertex,-,-,-
huggingface/instrublip-flan-t5-xl,instructblip-xl,Hugging Face: InstructBLIP XL,C,0.00000010,0.00000100,-,2048,512,VS,verified,huggingface,2024-10-01,Open-source InstructBLIP model with vision-language understanding,-,-,-
huggingface/idefics2-8b,idefics2-8b,Hugging Face: Idefics2 8B,C,0.00000008,0.00000080,-,4096,1024,VS,verified,huggingface,2024-11-15,French-centric multimodal LLM with vision,-,-,-
huggingface/idefics2-27b,idefics2-27b,Hugging Face: Idefics2 27B,C,0.00000030,0.00000300,-,4096,2048,VS,verified,huggingface,2024-11-15,Larger Idefics2 for advanced vision tasks,-,-,-
huggingface/phi-3-vision-128k,phi-3-vision-128k,Microsoft: Phi 3 Vision,C,0.00000050,0.00000500,-,128000,4096,VST,verified,huggingface,2024-12-01,Compact vision model from Microsoft with 128K context,-,-,-
huggingface/moondream2,moondream2,Moondream: Moondream2,C,0.00000001,0.00000010,-,2048,512,VS,verified,huggingface,2024-10-15,Ultra-lightweight vision model optimized for edge,-,-,-
cogvlm/cogvlm2-9b-instruct,cogvlm2-9b,Hugging Face: CogVLM2 9B,C,0.00000015,0.00000150,-,8192,2048,VST,verified,huggingface,2024-11-20,Chinese-optimized vision language model,-,-,-
yi/yi-vl-34b,yi-vl-34b,01.AI: Yi Vision 34B,C,0.00000100,0.00001000,-,8192,2048,VST,verified,openrouter,2024-12-10,Yi Vision Language model with strong OCR capabilities,-,-,-
deepseek/deepseek-vl2,deepseek-vl2,DeepSeek: DeepSeek-VL2,C,0.00000050,0.00000500,-,8192,2048,VST,verified,openrouter,2024-12-15,DeepSeek vision language model with multi-image support,-,-,-
xai/grok-vision,grok-vision,xAI: Grok Vision,C,0.00000500,0.00001500,-,128000,8192,VST,verified,openrouter,2024-12-20,xAI Grok multimodal model with real-time data,-,-,-
anthropic/claude3opus,anthropic-claude3-opus,Anthropic: Claude 3 Opus,L,0.01500000,0.07500000,-,200000,4096,VSTJKC,verified,anthropic,2024-03-04,Original Claude 3 Opus release,-,-,-
openai/gpt-4-32k-vision,gpt-4-32k-vision,OpenAI: GPT-4 32K Vision,L,0.01000000,0.03000000,-,32000,4096,VST,verified,openai,2024-08-01,GPT-4 with limited context for vision,-,-,-
anthropic/claude-3-haiku-vision,claude-3-haiku-vision,Anthropic: Claude 3 Haiku Vision,L,0.00025000,0.00125000,-,200000,1024,VSTJKC,verified,anthropic,2024-03-01,Lightweight Claude 3 with vision support,-,-,-
